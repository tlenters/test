[
["index.html", "Integration and harmonization of trait data from plant individuals across heterogeneous sources Introduction", " Integration and harmonization of trait data from plant individuals across heterogeneous sources Tim P. Lenters, Andrew Henderson, Caroline M. Dracxler, Guilherme A. Elias, Suzanne Mogue, Thomas L.P. Couvreur &amp; W. Daniel Kissling 2020-10-04 Introduction This tutorial gives an indepth explanation of how to use and implement the different aspects of the workflow as described in Lenters et al., (submitted) It consists of different chapters: How to use the metadataform How to implement forms into the thesauri Understanding and using the automated integration R-script Understanding the output tables from the workflow "],
["form.html", "Chapter 1 Metadata form 1.1 How to fill-out the form 1.2 Exporting data and changing features", " Chapter 1 Metadata form This chapter explains how to use the metadaform as a dataset owner and to integrate data from heteregonous sources. The form can be downloaded from the Github-page for this project. 1.1 How to fill-out the form 1.1.1 Dataset information To give information on the dataset spreadsheet as a whole, the block in the top-left of the form has to be filled in. This is used to index and add certain metadata information to be integrated by the automated R-script later on. Fig. 1 provides an example of how to fill out this block. “?” can be clicked to give information on the used terms. The coordinate reference system can be searched for in the search bar. Fig. 1. Example of a filled-out dataset information part of the metadata form (user input in red) 1.1.2 Matching column headers The dataset owner is expected to match the verbatim column headers from his/hers spreadsheet(s) to standardized trait- and metadata names described in the different categories. The form consists of four different categories: Traits Taxon Measurement or Fact Occurrence For the blue traits column the dataset owner matches a column header of a quantitative trait to standardized names that matches best with that verbatim trait name. The unit that was used to measure this trait is provided in the adjecent column. Examples would be e.g. cm, mm, m, count or degrees (Fig. 2). Column headers should exactly be copied to the metadataform (including symbols and/or capital letters). Fig. 2. Matching verbatim column headers to standardized term This has to be done in the same manner for the other three categories (excl. units). These categories describe metadata information instead of trait measurements. The yellow taxon category is used for columns that provide additional taxonomic information for a specimen. The orange measurement or fact category gives additional information at the single-measurement level or reported facts. The green occurrence category provides information on the observation context of individual organisms. If it is not clear what is meant by a certain standardized term, the can be clicked to give a definition and additional semantic information. 1.1.3 Propose new terms In the case that none of the standardized terms match a column header, they can “added” to the form. The verbatim column header (and unit in case of traits) are given at the “…” at the bottom of each category. A descriptive name for this terms should also be given (Fig. 3). Fig. 3. Adding not included column headers If all quantitative trait headers and metadata column headers are filled-out and matched to standardized terms, the form can be saved and returned to the sender. 1.2 Exporting data and changing features To export the data for a filled-out form and add or change features, several sheets are available. These can be accessed by right-clicking “Form” in the bottom left and selecting “Unhide…”. In the window that opens, three additional sheets can be unhidden (Fig. 4). Fig. 4. Unhiding metadata sheets 1.2.1 Exporting data (output) The output-sheet allows for easy extraction of the metadata filled-out in the form. The colored “metadata” column can be copied and pasted in the metadata thesaurus and the units column (only the part within the black box) in the units thesaurus (Fig. 5). These columns should be lined up with the trait and metadata terms given in the most left column. Both the metadata and the units thesaurus will be explained further in the next chapter (2). If the person who filled out the form has proposed new terms (1.1.3), these should be added manually to the thesauri. Fig. 5. Copying columns to designated thesauri 1.2.2 Changing CRS-list (coordinates) The coordinate-sheet holds a list of different coordinate reference systems. This list can be searched from the “dataset information” section (Fig. 1). These descriptions are later automatically translated to their respective EPSG-code1. This list should usually not be edited, but if necessary, names can be edited through the “Coordinate Projection System” column. New entries can be entered by adding a new row to the table, adding the name in the “Coordinate Projection System” column and adding the subsequent number in the “Search” column. Both “Options” and “Offset” should not be edited. 1.2.3 Editing term-URIs (URIs) This sheet connects URIs to terms shown in the form and links them to ontology defenitions and other semantic information. Where missing, URIs can be added to listed terms (these should refer to an online ontology). If new terms that are proposed (1.1.3) are suitable, the term and corresponding URI can be added at the bottom of their respective category. Derived from the make_EPSG() function in the rgdal package version 1.4-3. https://CRAN.R-project.org/package=rgdal↩ "],
["thesauri.html", "Chapter 2 Metadata thesauri 2.1 Integrating metadata form output 2.2 Adding new terms", " Chapter 2 Metadata thesauri This chapter explains how to integrate output data from the metadata form and add new terms. The thesauri can be downloaded from the Github-page for this project. 2.1 Integrating metadata form output Chapter 1.2.1 explains how to extract the output data from the metadataform. This output consists of two columns. The first (metadata) is copied to the “total_thesaurus.xlsx” and the second (units) to “units.xlsx”. In both cases, these columns should be lined up with the “names” column in both thesauri (Fig. 6). Fig. 6. Copying output columns to corresponding thesauri. 2.2 Adding new terms If new traits are proposed by the person who filled out the form, they should be added mannualy to both thesauri. 2.2.1 Metadata thesaurus In the case of the medata thesaurus, new traits or other terms should be added as a new row directly under the corresponding category (categories are shown by different colors; Fig. 7a). Other than copying the standardized name to the “names” column, the right category should be specified in the “category” column (trait, taxon, measurement or occurrence), the class of the column entries in the dataset spreadsheet in the “classes” column (character or numeric) and the URI in the “identifier” column (Fig. 7b). All this information will later be used for the automated integration through the R-script. Fig. 7. Adding new terms to metadata thesaurus. a) Adding form output for new terms to thesaurus. b) Entering additional information for new terms. 2.2.2 Units thesaurus Adding new terms to the units thesaurus can be done in a similar fashion, but only in the case of new terms of the “trait” category. New terms should also be added at the bottom of the “names” column. Other than the “Units” output part of the metadata form (2.1) now additional information has to be added. Important! The “names” column for both thesauri should align and terms should be listed in the same order. This is to make sure that the right unit is paired with each trait name in the R-script. "],
["data-integration.html", "Chapter 3 Data integration 3.1 Spreadsheet preparation 3.2 Loading and preparing input data 3.3 Integrating datasets", " Chapter 3 Data integration This chapter explains the different steps of the automated integration R-script. This script can be downloaded from the Github-page for this project. 3.1 Spreadsheet preparation Besides the two thesauri (chapter 2), the R-script also requires the plant trait spreadsheets containing all measurement data as input. A few requirements have to be met to make these spreadsheet suitable for integration: All spreadsheets have to be comma-seperated value (.csv) files. If not the case, these can easily be converted from e.g. Excel files. All values in columns assigned to the “trait” category should be in the same unit of measurement (e.g. not one value in meters and the next in centimeters). Columns assigned to the “trait” category should only contain numeric values. If the measurement unit is also give within a value cell, it should be removed. The unit of a certain column should be specified through the units thesaurus only. Within each individual spreadsheet, the use of decimal seperators should be consistent (not ‘,’ in one and ‘.’ in another column). 3.2 Loading and preparing input data 3.2.1 Installing and loading packages The following script checks if the required packages for this script are installed, and installs those that are missing. Packages are then loaded, the working directory is set and the validation function is sourced. ls &lt;- c(&quot;readxl&quot;,&quot;data.table&quot;,&quot;dplyr&quot;,&quot;reshape2&quot;,&quot;traitdataform&quot;,&quot;stringr&quot;,&quot;rgdal&quot;,&quot;Taxonstand&quot;,&quot;tidyverse&quot;,&quot;rangeBuilder&quot;) new.packages &lt;- ls[!(ls %in% installed.packages()[,&quot;Package&quot;])] if(length(new.packages)) install.packages(new.packages) library(readxl) library(data.table) library(dplyr) library(reshape2) library(traitdataform) library(stringr) library(rgdal) library(Taxonstand) library(tidyverse) setwd(&quot;~/traitData&quot;) source(&quot;validation_script.R&quot;) 3.2.2 Validate dataset and metadata thesaurus This function checks if all datasets are in the right format for the workflow and that the metadata thesaurus is filled out correctly. In the case of common mistakes (as in Fig. 2 of the manuscript) the name of the dataset and column header is given. It is also checked if column headers entered in the metadata thesaurus are present in each dataset. validate_metadata() 3.2.3 Loading thesauri and preperation read_excel() is used to load in both thesauri. Therefore, they don’t have to be converted to .csv files like the measurement spreadsheets. metadata &lt;- read_excel(&quot;thesauri/metadata.xlsx&quot;) units &lt;- read_excel(&quot;thesauri/units.xlsx&quot;) Several redundant rows and columns are stripped from both thesauri to make them machine-readable. This includes the removal of references, basisOfRecord and coordinates information. A data frame is constructed that relates verbatim trait names to standardized terms. total_df &lt;- metadata[-c(1:4),] #remove references, basisOfRecord and coordinates info id_df &lt;- total_df %&gt;% filter(category == &quot;trait&quot;) %&gt;% select(traitName = names, identifier) #df with trait names and URIs total_df$identifier &lt;- NULL #remove identifier info unit_df &lt;- units[-1,] #remove references All cleaned spreadsheets (3.1) should be in the same folder called “raw_datasets”. Their file path and names are loaded. A data frame is also made containing various metadata information for reach spreadsheet. datasets &lt;- list.files(&quot;raw_datasets&quot;, pattern = &quot;.csv$&quot;, full.names = TRUE) #list with file path and names dataset_names &lt;- gsub(&quot;raw_datasets/|.csv&quot;, &quot;&quot;, datasets) #names of all datasets metadata_df &lt;- metadata[1:4,] %&gt;% select(dataset_names) #df with metadata information 3.3 Integrating datasets The different datasets are integrated and combined with the use of a loop. Column header standardization, adding of metadata information, unit harmonization and the conversion to a long-table format are done seperately for every dataset and combined to a total dataframe after every iteration. An empty data frame is made to append all datasets to. ext_df &lt;- data.frame() #empty df used for row binding Column headers for a given dataset are selected and loaded from the corresponding .csv file. Numeric and character columns are loaded seperately and bound together. for (i in 1:length(datasets)){ #thesaurus subsets loop_thesaurus &lt;- total_df %&gt;% select(category, classes, names, verbatim = dataset_names[i]) %&gt;% drop_na() numeric_names &lt;- loop_thesaurus %&gt;% filter(classes == &quot;numeric&quot;) character_names &lt;- loop_thesaurus %&gt;% filter(classes == &quot;character&quot;) #read classes from dataset numeric_df &lt;- fread(input = datasets[i], select = numeric_names$verbatim, col.names = numeric_names$names, colClasses = &quot;numeric&quot;, encoding = &quot;UTF-8&quot;) character_df &lt;- fread(input = datasets[i], select = character_names$verbatim, col.names = character_names$names, colClasses = &quot;character&quot;, encoding = &quot;UTF-8&quot;) #bind for full dataset with standardized names dataset &lt;- cbind(numeric_df, character_df) Columns containing trait data are converted from wide to long format. Columns “traitValue” and “traitName” are added. #melt data_full to long table taxon_occ_meas &lt;- loop_thesaurus %&gt;% filter(category != &quot;trait&quot;) traits &lt;- loop_thesaurus %&gt;% filter(category == &quot;trait&quot;) data_melt &lt;- melt(data = dataset, id.vars = taxon_occ_meas$names, measure.vars = traits$names, value.name = &quot;traitValue&quot;, variable.name = &quot;traitName&quot;, variable.factor = FALSE) %&gt;% drop_na(traitValue) References, basis of record, coordinate system and SRS are added from the metadata thesaurus. #add references, basisOfRecord and CRS data_melt$references &lt;- metadata_df[1,i] #add reference as column data_melt$basisOfRecord &lt;- metadata_df[2,i] #add basisOfRecord column data_melt$verbatimCoordinateSystem &lt;- metadata_df[3,i] #add verbatimCoordinateSystem as column data_melt$verbatimSRS &lt;- metadata_df[4,i] #add verbatimSRS as column Measurement units are added as a column. These are standardized to “cm”. #add unit column loop_unit &lt;- unit_df %&gt;% select(traitName = names, traitUnit = dataset_names[i]) %&gt;% drop_na() #relate unit to traitName data_melt &lt;- full_join(data_melt, loop_unit, by = &quot;traitName&quot;) #add unit column by merging #standardize measurement units data_melt$traitValue &lt;- ifelse(data_melt$traitUnit == &quot;m&quot;, data_melt$traitValue*100, data_melt$traitValue) data_melt$traitValue &lt;- ifelse(data_melt$traitUnit == &quot;mm&quot;, data_melt$traitValue/10, data_melt$traitValue) data_melt$traitUnit &lt;- ifelse(data_melt$traitUnit == &quot;m&quot; | data_melt$traitUnit == &quot;mm&quot;, &quot;cm&quot;, data_melt$traitUnit) Add verbatim trait names as column. Trait identifiers are added. #add verbatim traitname column verba_name &lt;- select(traits, traitName = names, verbatimTraitName = verbatim) #df to relate traitname to verbatim traitname data_melt &lt;- full_join(data_melt, verba_name, by = &quot;traitName&quot;) #add verbatim traitname column by merging #add trait-identifier column data_melt &lt;- full_join(data_melt, id_df, by = &quot;traitName&quot;) data_melt &lt;- subset(data_melt, is.na(traitValue) == FALSE) Rows are bound for every dataset. #output df (used for core table and extensions) ext_df &lt;- bind_rows(ext_df, data_melt) } "],
["output-tables.html", "Chapter 4 Output tables 4.1 Taxon extension 4.2 Measurement or Fact extension 4.3 Occurrence extension 4.4 Core table", " Chapter 4 Output tables From the total table resulting from the loop, the core table and extension tables are made. These are all automatically saved as .csv files. 4.1 Taxon extension Scientific, species and genus names are added if not present. ext_df$scientificName &lt;- ifelse(ext_df$scientificName %in% NA, gsub(&quot;[[:punct:]]+&quot;, &quot;&quot;, paste(ext_df$genus, ext_df$specificEpithet)), gsub(&quot;[[:punct:]]+&quot;, &quot;&quot;, ext_df$scientificName)) #make scientific name if not present ext_df$genus &lt;- ifelse(ext_df$genus %in% NA, word(ext_df$scientificName, 1), ext_df$genus) #make genus name if not present ext_df$specificEpithet &lt;- ifelse(ext_df$specificEpithet %in% NA, word(ext_df$scientificName, 2), ext_df$specificEpithet) #make specific epithet if not present Taxonomic information from the GBIF taxonomic backbone is added (traitdataform) and a taxonID is made. taxa_std &lt;- standardise_taxa(ext_df) #add taxonomic info columns taxon_names &lt;- subset(metadata, category == &quot;taxon&quot;) #subset only columns with names of taxon category taxon_names &lt;- c(taxon_names$names) #vector with taxon names taxon_subset &lt;- select(taxa_std, one_of(taxon_names)) #only select columns with names in taxon vector taxa_df &lt;- taxa_std %&gt;% select(taxonID = taxonID, scientificNameStd = scientificNameStd, kingdom = kingdom, phylum = phylum, class = class, order = order, family = family) %&gt;% mutate_each(list(as.character)) taxa_bind &lt;- cbind(taxa_df, taxon_subset) #combine columns Taxon &lt;- distinct(taxa_bind) #only select unique rows Taxon$taxonID2 &lt;- seq(1:nrow(Taxon)) #add more specific taxonID ext_df2 &lt;- full_join(Taxon, taxa_std, by = c(colnames(Taxon[!colnames(Taxon) %in% &quot;taxonID2&quot;]))) #add taxonID2 column Taxonomic information from The Plant List is added (Taxonstand). tpl &lt;- TPL(splist = unique(Taxon$scientificName), corr = TRUE) #add taxonomic info form The Plant List tpl_merge &lt;- left_join(Taxon, tpl, by = c(&quot;scientificName&quot; = &quot;Taxon&quot;)) #merge with Taxon df Taxonomic information from the World Checklist of Vascular Plants is added. No package is available so the database is automatically downloaded and opened. Important! The WCVP database is from June 2020. If a new version is released, the file URL should be changed manually. temp_zip &lt;- tempfile() #make temporary files to story WCVP zip and text files temp_txt &lt;- tempfile() download.file(url = &quot;http://sftp.kew.org/pub/data-repositories/WCVP/wcvp_v2_jun_2020.zip&quot;, destfile = temp_zip) #download WCVP database unzip(zipfile = temp_zip, exdir = temp_txt) #unzip and save database as text file WCVP &lt;- fread(file.path(temp_txt, &quot;wcvp_export.txt&quot;)) #read WCVP text file unlink(c(temp_zip, temp_txt)) #remove temporary files wcvp_sub &lt;- subset(WCVP, family %in% Taxon$family &amp; rank == &quot;SPECIES&quot;) #subset WCVP database to only included family names present in the datasets and only species names wcvp_sub$accepted &lt;- ifelse(wcvp_sub$taxonomic_status == &quot;Accepted&quot;, wcvp_sub$taxon_name, wcvp_sub$taxon_name) #make column for all accepted scientific names wcvp_merge &lt;- left_join(tpl_merge, wcvp_sub, by = c(&quot;scientificName&quot; = &quot;taxon_name&quot;)) #merge with tpl_merge The “Taxon” extension table is made and saved as .csv file. Taxon2 &lt;- data.frame(taxonID = wcvp_merge$taxonID2, #df for Taxon extension verbatimScientificName = wcvp_merge$scientificName, scientificNameGBIF = wcvp_merge$scientificNameStd, scientificNameTPL = ifelse(wcvp_merge$Plant.Name.Index == &quot;FALSE&quot; &amp; wcvp_merge$Higher.level == &quot;FALSE&quot;, NA ,paste(wcvp_merge$New.Genus, wcvp_merge$New.Species)), scientificNameWCVP = wcvp_merge$accepted, verbatimInfraspecificEpithet = wcvp_merge$infraspecificEpithet, kingdom = wcvp_merge$kingdom, phylum = wcvp_merge$phylum, class = wcvp_merge$class, order = wcvp_merge$order, family = wcvp_merge$family.x, genus = wcvp_merge$genus.x, stringsAsFactors = F, wcvp_merge[setdiff(taxon_names, c(&quot;specificEpithet&quot;,&quot;infraspecificEpithet&quot;,&quot;scientificName&quot;,&quot;genus&quot;))], GBIFID = wcvp_merge$taxonID, TPLID = ifelse(wcvp_merge$New.ID == &quot;&quot;, NA, paste0(&quot;http://www.theplantlist.org/tpl&quot;,wcvp_merge$TPL.version,&quot;/record/&quot;, wcvp_merge$New.ID)), WCVPID = ifelse(wcvp_merge$accepted_kew_id == &quot;&quot;, paste0(&quot;http://powo.science.kew.org/taxon/urn:lsid:ipni.org:names:&quot;, wcvp_merge$kew_id), paste0(&quot;http://powo.science.kew.org/taxon/urn:lsid:ipni.org:names:&quot;, wcvp_merge$accepted_kew_id))) fwrite(Taxon2, &quot;output_tables/Taxon_ext.csv&quot;, row.names = FALSE) #write taxon extension file Example of the taxon extension table: ## Loading required package: knitr taxonID verbatimScientificName scientificNameGBIF scientificNameTPL scientificNameWCVP verbatimInfraspecificEpithet kingdom phylum class order family genus originalNameUsage morphotype verbatimTaxonRank GBIFID TPLID WCVPID 1 Attalea allenii Attalea allenii Attalea allenii Attalea allenii NA Plantae Tracheophyta Liliopsida Arecales Arecaceae Attalea A. allenii NA NA http://www.gbif.org/species/2732754 http://www.theplantlist.org/tpl1.1/record/kew-17762 http://powo.science.kew.org/taxon/urn:lsid:ipni.org:names:26553-2 2 Attalea amygdalina Attalea amygdalina Attalea amygdalina Attalea amygdalina NA Plantae Tracheophyta Liliopsida Arecales Arecaceae Attalea A. amygdalina NA NA http://www.gbif.org/species/2732713 http://www.theplantlist.org/tpl1.1/record/kew-17763 http://powo.science.kew.org/taxon/urn:lsid:ipni.org:names:664411-1 3 Attalea barreirensis Attalea barreirensis Attalea barreirensis Attalea barreirensis NA Plantae Tracheophyta Liliopsida Arecales Arecaceae Attalea A. barreirensis NA NA http://www.gbif.org/species/2732742 http://www.theplantlist.org/tpl1.1/record/kew-17766 http://powo.science.kew.org/taxon/urn:lsid:ipni.org:names:1014709-1 4 Attalea barreirensis Attalea barreirensis Attalea barreirensis Attalea barreirensis NA Plantae Tracheophyta Liliopsida Arecales Arecaceae Attalea NA NA NA http://www.gbif.org/species/2732742 http://www.theplantlist.org/tpl1.1/record/kew-17766 http://powo.science.kew.org/taxon/urn:lsid:ipni.org:names:1014709-1 5 Attalea butyracea Attalea butyracea Attalea butyracea Attalea butyracea NA Plantae Tracheophyta Liliopsida Arecales Arecaceae Attalea S. rostrata NA NA http://www.gbif.org/species/2732721 http://www.theplantlist.org/tpl1.1/record/kew-17772 http://powo.science.kew.org/taxon/urn:lsid:ipni.org:names:1172851-2 6 Attalea butyracea Attalea butyracea Attalea butyracea Attalea butyracea NA Plantae Tracheophyta Liliopsida Arecales Arecaceae Attalea S. butyracea NA NA http://www.gbif.org/species/2732721 http://www.theplantlist.org/tpl1.1/record/kew-17772 http://powo.science.kew.org/taxon/urn:lsid:ipni.org:names:1172851-2 4.2 Measurement or Fact extension The “Measurement or Fact” extension table is made and saved as an .csv file. subset_meas &lt;- subset(taxon_occ_meas, category == &quot;measurement&quot;) #subset only columns with names of measurement category vector_meas &lt;- c(subset_meas$names) #vector with measurement names Measurement &lt;- data.frame(ext_df2[vector_meas], #df with all measurement or fact info basisOfRecord = ext_df2$basisOfRecord, references = ext_df2$references) Measurement &lt;- distinct(Measurement) #select only distinct rows Measurement$measurementID &lt;- seq(nrow(Measurement)) #add measurementID Measurement &lt;- Measurement %&gt;% select(measurementID, everything()) #measurementID as first column write.csv(Measurement, &quot;output_tables/Measurement_or_Fact_ext.csv&quot;, fileEncoding = &quot;Latin1&quot;, row.names = FALSE) #write measurement or fact extension file ext_df3 &lt;- full_join(Measurement, ext_df2, by = c(colnames(Measurement[!colnames(Measurement) %in% &quot;measurementID&quot;]))) Example of the measurement or fact table: measurementID measurementDeterminedBy basisOfRecord references 1 de Nevers PreservedSpecimen Henderson, A. (2020a). A revision of Attalea (Arecaceae, Arecoideae, Cocoseae, Attaleinae). Phytotaxa, 444(1), 1-76. 2 Hammel PreservedSpecimen Henderson, A. (2020a). A revision of Attalea (Arecaceae, Arecoideae, Cocoseae, Attaleinae). Phytotaxa, 444(1), 1-76. 3 Croat PreservedSpecimen Henderson, A. (2020a). A revision of Attalea (Arecaceae, Arecoideae, Cocoseae, Attaleinae). Phytotaxa, 444(1), 1-76. 4 Sugden PreservedSpecimen Henderson, A. (2020a). A revision of Attalea (Arecaceae, Arecoideae, Cocoseae, Attaleinae). Phytotaxa, 444(1), 1-76. 5 Anderson PreservedSpecimen Henderson, A. (2020a). A revision of Attalea (Arecaceae, Arecoideae, Cocoseae, Attaleinae). Phytotaxa, 444(1), 1-76. 6 Duke PreservedSpecimen Henderson, A. (2020a). A revision of Attalea (Arecaceae, Arecoideae, Cocoseae, Attaleinae). Phytotaxa, 444(1), 1-76. 4.3 Occurrence extension Verbatim SRSs are standardized to EPSG-codes. Misspelled country names are corrected and standardized. EPSG_df &lt;- make_EPSG() #download EPSG database EPSG_df$verbatimSRS &lt;- gsub(&quot;# &quot;,&quot;&quot;, EPSG_df$note) #remove symbols EPSG_df[,c(&quot;note&quot;,&quot;prj4&quot;)] &lt;- NULL #remove note and prj4 columns EPSG_df &lt;- EPSG_df[!duplicated(EPSG_df[,&quot;verbatimSRS&quot;]),] #remove duplicate verbatimSRS values ext_df3 &lt;- left_join(ext_df3, EPSG_df, by = &quot;verbatimSRS&quot;) #merge by verbatimSRS ext_df3$geodeticDatum &lt;- ext_df3$code #rename EPSG code column ext_df3$code &lt;- NULL ext_df3$verbatimSRS &lt;- NULL ext_df3$geodeticDatum &lt;- ifelse(ext_df3$geodeticDatum %in% NA, &quot;unknown&quot;, as.character(paste0(&quot;EPSG:&quot;,ext_df3$geodeticDatum))) #add &quot;EPSG:&quot; tag ext_df3$country &lt;- rangeBuilder::standardizeCountry(ext_df3$verbatimCountry, fuzzyDist = 5) #standardize country names The “Occurrence” extension table is made and saved as an .csv file. subset_occ &lt;- subset(taxon_occ_meas, category == &quot;occurrence&quot;) #subset only columns with names of occurrence category vector_occ &lt;- c(subset_occ$names) #vector with occurrence names Occurrence &lt;- data.frame(ext_df3[vector_occ], country = ext_df3$country, geodeticDatum = ext_df3$geodeticDatum, stringsAsFactors = FALSE) #df with all occurrence info Occurrence &lt;- distinct(Occurrence) #only select unique rows Occurrence$occurrenceID &lt;- seq(1:nrow(Occurrence)) #add occurrenceID Occurrence &lt;- Occurrence %&gt;% select(occurrenceID, everything()) #move ID to first position fwrite(Occurrence, &quot;output_tables/Occurrence_ext.csv&quot;, row.names = FALSE) #write occurrence extension file ext_df4 &lt;- full_join(Occurrence, ext_df3, by = c(colnames(Occurrence[!colnames(Occurrence) %in% &quot;occurrenceID&quot;]))) #occurrenceID column Example of the occurrence table: occurrenceID identificationID recordNumber institutionCode verbatimLatitude verbatimLongitude verbatimElevation verbatimCountry country geodeticDatum 1 684 4735 MO 9.40 -79.13 90 Panama PANAMA EPSG:4326 2 7 4152 NY 9.31 -78.91 300 Panama PANAMA EPSG:4326 3 718 3639 MO 9.31 -78.25 350 Panama PANAMA EPSG:4326 4 678 7301 MO 9.31 -78.91 350 Panama PANAMA EPSG:4326 5 720 7191 MO 9.43 -79.11 NA Panama PANAMA EPSG:4326 6 660 7766 MO 8.95 -83.11 NA Costa Rica COSTA RICA EPSG:4326 4.4 Core table The core table is made from the total table and saved as .csv file. It is linked to the extension table via the “taxonID”, “measurementID” and “occurrenceID” columns. core_table &lt;- ext_df4 %&gt;% select(scientificName = scientificNameStd,#df with all core values and ID&#39;s verbatimScientificName = scientificName, verbatimTraitName = verbatimTraitName, traitName = traitName, traitValue = traitValue, traitUnit = traitUnit, traitID = identifier, taxonID = taxonID2, measurementID = measurementID, occurrenceID = occurrenceID) fwrite(core_table, &quot;output_tables/core_table.csv&quot;, row.names = FALSE) #write file with core values and ID&#39;s Example of the core table: scientificName verbatimScientificName verbatimTraitName traitName traitValue traitUnit traitID taxonID measurementID occurrenceID Attalea allenii Attalea allenii Stflowlen Staminate_flower_length 0.98 cm NA 1 1 1 Attalea allenii Attalea allenii Straclen Staminate_rachilla_length 3.00 cm NA 1 1 1 Attalea allenii Attalea allenii Petiole Petiole_length 150.00 cm http://purl.obolibrary.org/obo/TO_0000766 1 1 2 Attalea allenii Attalea allenii Seeds Seed_count 3.00 count http://purl.obolibrary.org/obo/TO_0000445 1 1 2 Attalea allenii Attalea allenii Pinwid Median_leaflet_width 3.80 cm NA 1 1 2 Attalea allenii Attalea allenii Fruitdiam Fruit_width 3.60 cm http://purl.obolibrary.org/obo/TO_0002627 1 1 2 "]
]
